{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "Prensent Problem:\r\n",
    "    1) need to formalize file name:\r\n",
    "        a) blank & Chinese blank\r\n",
    "        b) return , enter symbol;\r\n",
    "        c) \\ and / sym;\r\n",
    "        d) other invalid file name sym;\r\n",
    "    2) valid filename regex:\r\n",
    "        [\\w]{6:30}\r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from bs4 import BeautifulSoup\r\n",
    "import re\r\n",
    "import requests as rq\r\n",
    "\r\n",
    "with open('D:\\haruk\\Documents\\PythonCodes\\BiLab_publication_page.html',encoding='utf-8') as html:\r\n",
    "    soup= BeautifulSoup(html,'html.parser')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "html.closed"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def customizedCDN_4_soupFindAll(tag):\r\n",
    "    if tag.name==\"p\" and tag.has_attr('class') and not tag.contents[0].name==\"strong\" and not tag.has_attr('align'): \r\n",
    "        return True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cstmdcdn(string):\r\n",
    "    if re.match(r'B[iI]',string):\r\n",
    "        return True"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "sfa_lst=soup(customizedCDN_4_soupFindAll)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "print(sfa_lst[96].a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "source": [
    "reslst=[]\r\n",
    "imlst=[]\r\n",
    "for i in sfa_lst:\r\n",
    "            if not i.a == None:\r\n",
    "                hpath = i.a.attrs['href']\r\n",
    "            else:\r\n",
    "                hpath = None\r\n",
    "            \r\n",
    "            if len(i) == None or len(i) == 1:\r\n",
    "                fname=i.string\r\n",
    "            else:\r\n",
    "                for k in i.strings:\r\n",
    "                    imlst.append(k)\r\n",
    "                fname=\".\".join(imlst)\r\n",
    "                imlst=[]\r\n",
    "            reslst.append([fname,hpath])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# -*- coding: utf-8 -*-\r\n",
    "'write the Comparasion List into xlsx'\r\n",
    "\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "fnames=[]\r\n",
    "durls=[]\r\n",
    "for i in reslst:\r\n",
    "    fnames.append(i[0])\r\n",
    "    durls.append(i[1])\r\n",
    "\r\n",
    "datfra=pd.DataFrame({'filename':fnames,'urls':durls})\r\n",
    "datfra.to_excel('test1.xlsx') # default path = D://.../pathoncodes"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "lst1=reslst[1]\r\n",
    "print(lst1[0])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'explicitly check for unvalid syms'\r\n",
    "regex=re.compile(r'pdf')\r\n",
    "itera=0\r\n",
    "for ls in reslst:\r\n",
    "    match=regex.findall(ls[0])\r\n",
    "    if match:\r\n",
    "        chklst=[itera,match]\r\n",
    "        print(chklst)\r\n",
    "        itera+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "source": [
    "usualUnvalidSyms=re.compile(r'\\xa0|\\u3000|\\r+|\\n+')\r\n",
    "'Attention here! : above are usual invalid syms for filename'\r\n",
    "for ls in reslst:\r\n",
    "    ls[0]=usualUnvalidSyms.sub(string=ls[0],repl='')\r\n",
    "    ls[0]=re.sub(pattern=r'\\s+|[\\/:*?\"<>|]+',repl='_',string=ls[0])\r\n",
    "    ls[0]=ls[0].strip('_.pdf') + '.pdf'\r\n",
    "\r\n",
    "for ls in reslst:\r\n",
    "    matchchk=re.match('^\\.pdf$',ls[0])\r\n",
    "    if matchchk:\r\n",
    "        ls[0]=None"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "'findDownloadPath'\r\n",
    "\r\n",
    "homepage='http://bilab.bnu.edu.cn/'\r\n",
    "root='D:/haruk/Documents/PythonCodes/'\r\n",
    "lst1=reslst[1]\r\n",
    "d_url = homepage + lst1[1]\r\n",
    "d_path = root + lst1[0]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "source": [
    "import requests as rq\r\n",
    "htmli=rq.get(d_url,headers={\"user-agent\":\"chrome/10\"},timeout=30)\r\n",
    "htmli.raise_for_status() # If status != 200, cause HTTPError\r\n",
    "with open(d_path,\"wb\") as f:\r\n",
    "    for chunk in htmli.iter_content(chunk_size=8192):\r\n",
    "        f.write(chunk)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "'Alternative Codes'\r\n",
    "\r\n",
    "def formatingLists(soup_findall_lst):\r\n",
    "    reslst=[]\r\n",
    "    imlst=[]\r\n",
    "    try:\r\n",
    "        for i in soup_findall_lst:\r\n",
    "            if not i.a == None:\r\n",
    "                hpath = i.a.attrs['href']\r\n",
    "            else:\r\n",
    "                hpath = None\r\n",
    "            if len(i) == None or len(i) == 1:\r\n",
    "                fname=i.string\r\n",
    "            else:\r\n",
    "                for k in i.strings:\r\n",
    "                    imlst.append(k)\r\n",
    "                imstr=\".\".join(imlst).replace(' ','').replace('/','').replace('\\\\','')\r\n",
    "                if imstr.endswith('.pdf'):\r\n",
    "                    fname=imstr\r\n",
    "                else:\r\n",
    "                    fname=imstr+'.pdf'\r\n",
    "                imlst=[]\r\n",
    "            reslst.append(fname,hpath)\r\n",
    "            return reslst\r\n",
    "    except:\r\n",
    "        print(\"Lists Formating Error\")\r\n",
    "\r\n",
    "def findDownloadPath(lst):\r\n",
    "    hp='http://bilab.bnu.edu.cn/'\r\n",
    "    root='D:/haruk/Documents/PythonCodes/'\r\n",
    "    durl=hp+lst[1]\r\n",
    "    dpath=root+lst[2]\r\n",
    "    return [durl,dpath]\r\n",
    "\r\n",
    "def getPDFdown(url,path):\r\n",
    "    try:\r\n",
    "        html=rq.get(url,headers={\"user-agent\":\"chrome/10\"},timeout=30)\r\n",
    "        html.raise_for_status() # If status != 200, cause HTTPError\r\n",
    "        with open(path,\"x\") as f:\r\n",
    "            f.write(html.content)\r\n",
    "            f.close()\r\n",
    "    except:\r\n",
    "        return \"Error occurred\"\r\n",
    "\r\n",
    "def mainprocess():\r\n",
    "    url=\"http://bilab.bnu.edu.cn/publication.html\"\r\n",
    "    html=getHTMLtext(url)\r\n",
    "    \r\n",
    "    soup=BeautifulSoup(html,\"html.parser\")\r\n",
    "    \r\n",
    "    sfa_lst=soup(name_p_has_no_strong_child)\r\n",
    "    print(\"Please check for the length of Soup_find_all lists is now: {}\".format(len(sfa_lst)))\r\n",
    "\r\n",
    "    comparLsts=formatingLists(sfa_lst)\r\n",
    "    \r\n",
    "    # Initiating download:\r\n",
    "    itrial=0\r\n",
    "    for ls in comparLsts:\r\n",
    "        try:\r\n",
    "            [durl,dpath]=findDownloadPath(ls)\r\n",
    "            getPDFdown(durl,dpath)\r\n",
    "            itrial+=1\r\n",
    "        except:\r\n",
    "            print(\"Error occurred at Comparison Table No.:{}\".format(itrial))\r\n",
    "            continue"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "4f8763616d36299a7e67065bbff61b4594b946871d4c1b06c8acd4b8a7e0d76f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}