{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTES:\n",
    "This module aims to be used in following situation: \n",
    "- when a network graph in obsidian is already complete, but still need to append several new records from WoS, then use this module to read records that are directly downloaded from WoS.\n",
    "\n",
    "### REQUIREMENT:\n",
    "- should fit with format of the Tab-Deliminated-File that is directly downloaded from WoS.\n",
    "### ***better to be a more general reader for this kind of text***.\n",
    "\n",
    "### PROBLEM:\n",
    "* The records directly from WoS have different column names in several places, relative to HistCite records:\n",
    "    - NR == NCR\n",
    "    - no: LCS, LCR\n",
    "* Notify: it seems like: if the SOURCE name of a record is already a abbreviated form under columns of 'SO', then the 'J9' column of this record would be empty; so when using 'J9', it is better to check for `None`;\n",
    "* Waited for solving: the method of use template now is a little bit complicated and unprettified; \n",
    "- maybe to use a separate function to process the print;\n",
    "- or remove the `usecols` and to read all columns into the dataframe, and call specific element directly using the column name of it.\n",
    "### CODES:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#git add\n",
    "def formating_from_TabDeliFile_to_md(csv_path: str, use_cols: list, templ:str):\n",
    "    '''\n",
    "    Usage: extract inforamtion from csv and write to markdown according with the given template;\n",
    "\n",
    "    :param use_cols: \n",
    "        should include all information that you intend to show in the markdown;\n",
    "        should always include 'J9', 'CR' and put them in the end of list;\n",
    "    \n",
    "    Notes: Output path is assigned to: './Project/'\n",
    "    '''\n",
    "\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    dtfm = pd.read_table(\n",
    "        csv_path,\n",
    "        header=0, index_col=False, usecols=use_cols, keep_default_na=False, encoding='UTF_8'\n",
    "    )\n",
    "\n",
    "    lst_output = []\n",
    "    for row in range(dtfm.shape[0]): # single for_loop for all process\n",
    "        au = dtfm.loc[row]['AU'].split('; ')[0].replace(',', '')        \n",
    "\n",
    "        filename = au +', '+ str(dtfm.loc[row]['PY']) +', '+ dtfm.loc[row]['SO'] +'.md'\n",
    "\n",
    "        templst_1 = []\n",
    "        for each_CR in dtfm.loc[row]['CR'].split('; '):\n",
    "            temp_CR = re.sub(r'[\\[\\]]+', repl='', string=each_CR)\n",
    "            templst_2 = []\n",
    "            for part in temp_CR.split(', '):\n",
    "                if not re.match(r'^[PV][\\d]*$|^DOI ', part): # ths ver trying to remove DOI in filename & content link\n",
    "                    templst_2.append(part)\n",
    "            templst_1.append('[[' + ', '.join(templst_2) + ']]')\n",
    "        output_CR = '\\n'.join(templst_1)\n",
    "        \n",
    "        output_UT = dtfm.loc[row]['UT'].replace('WOS:','')\n",
    "\n",
    "        filecontent = templ.format(\n",
    "            dtfm.loc[row][use_cols[0]],       #0\n",
    "            dtfm.loc[row][use_cols[1]],       #1\n",
    "            dtfm.loc[row][use_cols[2]],       #2\n",
    "            dtfm.loc[row][use_cols[3]],       #3\n",
    "            dtfm.loc[row][use_cols[4]],       #4\n",
    "            dtfm.loc[row][use_cols[5]],       #5\n",
    "            dtfm.loc[row][use_cols[6]],       #6\n",
    "            dtfm.loc[row][use_cols[7]],       #7\n",
    "            dtfm.loc[row][use_cols[8]],       #8\n",
    "            output_UT,                        #9\n",
    "            str(dtfm.loc[row][use_cols[10]]), #10\n",
    "            str(dtfm.loc[row][use_cols[11]]), #11\n",
    "            output_CR,                        #12\n",
    "        )\n",
    "\n",
    "        lst_output.append((filename, filecontent))\n",
    "    \n",
    "    # save files:\n",
    "    for i in range(len(lst_output)):\n",
    "        with open(f'./Projects/{lst_output[i][0]}', 'xt', encoding='UTF_8') as f:\n",
    "            f.write(lst_output[i][1])\n",
    "            f.close()\n",
    "    # return lst_output, dtfm\n",
    "\n",
    "def set_tag_to_Bi(authors:str):\n",
    "    import re\n",
    "\n",
    "    lst_au = []\n",
    "    for author in authors.split('; '):\n",
    "        if re.match(r'B[iI], YC?|B[iI], Yanchao', author):\n",
    "            lst_au.append('#BiYC')\n",
    "        else:\n",
    "            lst_au.append(author)\n",
    "    return '; '.join(lst_au)\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "Initiation\n",
    "'''\n",
    "\n",
    "path = 'Data/CiteAnalysisData/Della_2018_TDF.txt'\n",
    "#       0     1    2   3    4    5    6    7    8    9    10   11   12   13     \n",
    "use = ['TI','AU','PY','DT','SO','AB','DE','ID','DI','UT','NR','TC','CR']\n",
    "template = '''---\n",
    "Alias: NeuroBasis\n",
    "TC: {11}\n",
    "---\n",
    "#show_on\n",
    "**Title**: {0}\n",
    "**Authors**: {1}\n",
    "**PubYear**: #PY{2}\n",
    "**DocType**: #{3}\n",
    "**Journal**: {4}\n",
    "> **Abstract**:\n",
    "> {5}\n",
    "\n",
    "**AuthKW**: {6}\n",
    "**Keywords+**: {7}\n",
    "**DOI**: {8}\n",
    "**WoS**: {9}\n",
    "\n",
    "#### CitedRefs: ({10})\n",
    "{12}'''\n",
    "\n",
    "formating_from_TabDeliFile_to_md(csv_path=path, use_cols=use, templ=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "use_cols = ['TI','AU','PY','DT','SO','AB','DE','ID','DI','UT','NCR','TC','LCS','LCR','J9','CR']\n",
    "csv_path = 'Data/CiteAnalysisData/Della_2018_TDF.txt'\n",
    "dtfm = pd.read_table(\n",
    "        csv_path,\n",
    "        header=0, index_col=False, keep_default_na=False, encoding='UTF_8'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data/CiteAnalysisData/Della_2018_TDF.txt', 'rt', encoding='utf_8') as f:\n",
    "    row_idx = f.readline()\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    NEUROIMAGE\n",
       "Name: SO, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtfm.loc[:, 'SO']"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f8763616d36299a7e67065bbff61b4594b946871d4c1b06c8acd4b8a7e0d76f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
