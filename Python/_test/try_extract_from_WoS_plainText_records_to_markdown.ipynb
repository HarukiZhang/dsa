{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "use = ['PT', 'AU', 'TI', 'SO', 'J9', 'DT', 'DE', 'ID', 'AB','CR','NCR','TC','BP','EP','PY','DI','UT','LCS','LCR']\n",
    "dtfm = pd.read_csv(\n",
    "    'Data/20210825_LCS100+allBIYC.csv',\n",
    "    header=0, index_col=False, usecols=use, keep_default_na=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "git add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customized extraction from WoS txt to lst\n",
    "import re\n",
    "\n",
    "def extract_infos_by_readlines(f):\n",
    "    f.seek(0)\n",
    "    lst_AU, lst_J9, lst_CR, lst_PY, lst_SO, lst_DI = [], [], [], [], [], []\n",
    "    count_SO, count_J9 = 0, 1\n",
    "    for line in f:\n",
    "        imlst = []\n",
    "        if re.match(r'AU ', line):\n",
    "            imlst.append(line[3:-1])\n",
    "            line = f.readline()\n",
    "            while re.match(r'   ', line):\n",
    "                imlst.append(line[3:-1])\n",
    "                line = f.readline() # when match==False,one more ln will be read\n",
    "                # discard ths ln bcs not interested\n",
    "            lst_AU.append(imlst)\n",
    "        elif re.match(r'CR ', line):\n",
    "            imlst.append(line[3:-1])\n",
    "            line = f.readline()\n",
    "            while re.match(r'   ', line):\n",
    "                imlst.append(line[3:-1])\n",
    "                line = f.readline() # here also discard th ln after\n",
    "            lst_CR.append(imlst)\n",
    "        elif re.match(r'J9 ', line):\n",
    "            if not count_J9 == count_SO: # Notify count_J9 initiate from 1, count_SO form 0\n",
    "                # bcs in the text, ln SO is below the ln J9\n",
    "                # when two are not equal, J9 must be absent in the last paper\n",
    "                lst_J9.append([count_J9, None])\n",
    "                count_J9 += 1\n",
    "            lst_J9.append([count_J9, line[3:-1]])\n",
    "            count_J9 += 1\n",
    "        elif re.match(r'PY ', line):\n",
    "            lst_PY.append(line[3:-1])\n",
    "        elif re.match(r'SO ', line):\n",
    "            lst_SO.append(line[3:-1])\n",
    "            count_SO += 1\n",
    "        elif re.match(r'DI ', line):\n",
    "            lst_DI.append(line[3:-1])\n",
    "    return lst_AU, lst_J9, lst_CR, lst_PY, lst_SO, lst_DI\n",
    "\n",
    "def extract_infos_by_re_search(f):\n",
    "    f.seek(0)\n",
    "    text = f.read()\n",
    "    papers = re.split(r'\\nAU ', string=text)[1:] # discard the first split bcs its useless info\n",
    "    lst_titles = []\n",
    "    for i in range(len(papers)):\n",
    "        # papers[i] = 'AU ' + papers[i] # op .split deleted 'AU ', here we plus it back\n",
    "        au = re.search(r'^.*\\nAF', papers[i], flags=re.S).group(0)[:-3]\n",
    "        jn = re.search(r'\\nSO .*?\\n.*?\\n', papers[i]).group(0)[1:-1]\n",
    "        cr = re.search(r'CR .*NR', papers[i], flags=re.S).group(0)[:-3]\n",
    "        py = re.search(r'\\nPY .*', papers[i]).group(0)[1:]\n",
    "        di = re.search(r'\\nDI .*', papers[i]).group(0)[1:]\n",
    "        lst_titles.append([au, jn, cr, py, di])\n",
    "    return lst_titles\n",
    "\n",
    "\n",
    "f = open('Data\\CiteAnalysisData\\Della_2018.txt', 'rt', encoding='UTF_8', newline=None)\n",
    "\n",
    "lst_titles = extract_infos_by_re_search(f)\n",
    "lst_AU, lst_J9, lst_CR, lst_PY, lst_SO, lst_DI = extract_infos_by_readlines(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def formating_from_csv_to_md(csv_path: str, use_cols: list, templ:str):\n",
    "    '''\n",
    "    Usage: extract inforamtion from csv and write to markdown according with the given template;\n",
    "\n",
    "    :param use_cols: \n",
    "        should include all information that you intend to show in the markdown;\n",
    "        should always include 'J9', 'CR' and put them in the end of list;\n",
    "    \n",
    "    Notes: Output path is assigned to: './Project/'\n",
    "    '''\n",
    "\n",
    "    import re\n",
    "    import pandas as pd\n",
    "\n",
    "    dtfm = pd.read_csv(\n",
    "        csv_path,\n",
    "        header=0, index_col=False, usecols=use_cols, keep_default_na=False\n",
    "    )\n",
    "\n",
    "    lst_output = []\n",
    "    for row in range(dtfm.shape[0]): # single for_loop for all process\n",
    "        au = dtfm.loc[row]['AU'].split('; ')[0].replace(',', '')\n",
    "        \n",
    "        filename = au +', '+ str(dtfm.loc[row]['PY']) +', '+ dtfm.loc[row]['J9'] +'.md'\n",
    "        \n",
    "        templst_1 = []\n",
    "        for each_CR in dtfm.loc[row]['CR'].split('; '):\n",
    "            temp_CR = re.sub(r'[\\[\\]]+', repl='', string=each_CR)\n",
    "            templst_2 = []\n",
    "            for part in temp_CR.split(', '):\n",
    "                if not re.match(r'^[PV][\\d]*$|^DOI ', part): # ths ver trying to remove DOI in filename & content link\n",
    "                    templst_2.append(part)\n",
    "            templst_1.append('[[' + ', '.join(templst_2) + ']]')\n",
    "        output_CR = '\\n'.join(templst_1)\n",
    "        \n",
    "        filecontent = templ.format(\n",
    "            dtfm.loc[row][use_cols[0]],\n",
    "            dtfm.loc[row][use_cols[1]],\n",
    "            dtfm.loc[row][use_cols[2]],\n",
    "            dtfm.loc[row][use_cols[3]],\n",
    "            dtfm.loc[row][use_cols[4]],\n",
    "            dtfm.loc[row][use_cols[5]],\n",
    "            dtfm.loc[row][use_cols[6]],\n",
    "            dtfm.loc[row][use_cols[7]],\n",
    "            dtfm.loc[row][use_cols[8]],\n",
    "            dtfm.loc[row][use_cols[9]],\n",
    "            output_CR\n",
    "        )\n",
    "\n",
    "        lst_output.append((filename, filecontent))\n",
    "    \n",
    "    # save files:\n",
    "    for i in range(len(lst_output)):\n",
    "        with open(f'./Projects/{lst_output[i][0]}', 'xt', encoding='UTF_8') as f:\n",
    "            f.write(lst_output[i][1])\n",
    "            f.close()\n",
    "\n",
    "    return lst_output, dtfm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "path = 'Data/20210825_LCS100+allBIYC.csv'\n",
    "use = ['TI','AU','PY','DT','SO','AB','DE','ID','DI','UT','J9','CR']\n",
    "template = '''---\n",
    "Show:off\n",
    "---\n",
    "**Title**: {0}\n",
    "**Authors**: {1}\n",
    "**PubYear**: #PY{2}\n",
    "**DocType**: {3}\n",
    "**Journal**: {4}\n",
    "> **Abstract**:\n",
    "> {5}\n",
    "\n",
    "**AuthKW**: {6}\n",
    "**Keywords+**: {7}\n",
    "**DOI**: {8}\n",
    "**WoSNo**: {9}\n",
    "\n",
    "#### CitedRefs:\n",
    "{10}'''\n",
    "\n",
    "cklst, dtfm = formating_from_csv_to_md(csv_path=path, use_cols=use, templ=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prototype of formatting_from_csv...\n",
    "import re\n",
    "\n",
    "test_dtfm = dtfm.copy()\n",
    "\n",
    "\n",
    "view_CR = test_dtfm['CR']\n",
    "views = test_dtfm.loc[:][['AU','J9','PY']]\n",
    "\n",
    "lst_filename = []\n",
    "lst_CR = []\n",
    "lst_filecontent = []\n",
    "\n",
    "for row in range(test_dtfm.shape[0]):\n",
    "    if not view_CR[row] == '':\n",
    "        templst_1 = []\n",
    "        for each_CR in view_CR[row].split('; '):\n",
    "            temp_CR = re.sub(r'[\\[\\]]+', repl='', string=each_CR)\n",
    "            templst_2 = []\n",
    "            for part in each_CR.split(', '):\n",
    "                if not re.match(r'^[PV][\\d]*$|^DOI ', part):\n",
    "                    templst_2.append(part)\n",
    "            templst_1.append('[[' + ', '.join(templst_2) + ']]')\n",
    "        lst_CR.append('\\n'.join(templst_1))\n",
    "    else:\n",
    "        lst_CR.append(None) # substitute '' with None\n",
    "\n",
    "    au = views.loc[row]['AU'].split('; ')[0].replace(',', '') + ', '\n",
    "    lst_filename.append(au + str(views.loc[row]['PY']) +', '+ views.loc[row]['J9'] +'.md')\n",
    "\n",
    "    lst_filecontent.append(\n",
    "f'''\n",
    "---\n",
    "Show: off\n",
    "title: {au + str(views.loc[row]['PY']) +', '+ views.loc[row]['J9']}\n",
    "---\n",
    "Title:: {dtfm.loc[row]['TI']}\n",
    "Authors:: {dtfm.loc[row]['AU']}\n",
    "PubYear:: #PY{dtfm.loc[row]['PY']}\n",
    "Journal:: {dtfm.loc[row]['SO']}\n",
    "DOI:: {dtfm.loc[row]['DI']}\n",
    "Keywords_I:: {dtfm.loc[row]['DE']}\n",
    "Keywords_II:: {dtfm.loc[row]['ID']}\n",
    "Abstract:: {dtfm.loc[row]['AB']}\n",
    "CitedRefs:\n",
    "{lst_CR[row]}\n",
    "'''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Old version: Formatting info lists\n",
    "lst_resAU =[]\n",
    "for item in lst_AU:\n",
    "    lst_resAU.append(item[0].replace(',', '') + ', ')\n",
    "\n",
    "lst_resJ9 = []\n",
    "for item in lst_J9:\n",
    "    if item[1]:\n",
    "        lst_resJ9.append([item[0], item[1] + ', '])\n",
    "    else:\n",
    "        lst_resJ9.append([item[0], None])\n",
    "\n",
    "for i in range(len(lst_resJ9)):\n",
    "    if not lst_resJ9[i][1] and lst_SO[i]:\n",
    "        lst_resJ9[i][1] = lst_SO[i] + ', '\n",
    "\n",
    "lst_resPY = []\n",
    "for item in lst_PY:\n",
    "    lst_resPY.append(item + ', ')\n",
    "\n",
    "lst_resDI = []\n",
    "for item in lst_DI:\n",
    "    valid_name = re.sub(repl='_', pattern=r'[\\\\\\/:*?\"<>|\\s]+', string=item) # invalid: [\\/:*?\"<>|.] and space chr\n",
    "    lst_resDI.append('DOI_' + valid_name)\n",
    "\n",
    "'''\n",
    "Formating for File Saving\n",
    "'''\n",
    "# split each Citation string for easily popping out unwanted parts\n",
    "# re.match set the rule to pop out parts and check invalid characters\n",
    "# finally join togather to single string with '\\n'\n",
    "lst_resCR = []\n",
    "for row in lst_CR:\n",
    "    imlst = []\n",
    "    for cr in row:\n",
    "        im2lst = []\n",
    "        for part in cr.split(', '):\n",
    "            if not re.match(r'^[PV][\\d]*$', part):\n",
    "                if re.match(r'^DOI ', part):\n",
    "                    part = re.sub(repl='_', pattern=r'[\\\\\\/:*?\"<>|\\s]+', string=part)\n",
    "                im2lst.append(part)\n",
    "        imlst.append('[[' + ', '.join(im2lst) + ']]')\n",
    "    lst_resCR.append('\\n'.join(imlst))\n",
    "lst_filename = []\n",
    "for i in range(len(lst_resAU)):\n",
    "    lst_filename.append(lst_resAU[i] + lst_resPY[i] + lst_resJ9[i][1] + lst_resDI[i])\n",
    "\n",
    "lst_file_AU = []\n",
    "for item in lst_AU:\n",
    "    lst_file_AU.append('\\n'.join(item))\n",
    "\n",
    "lst_filecontent = []\n",
    "for i in range(len(lst_resAU)):\n",
    "    lst_filecontent.append(\n",
    "        'Auther:\\n' + lst_file_AU[i] +\n",
    "        '\\nPublish Year:\\n'+ lst_resPY[i] +\n",
    "        '\\nJournal:\\n'+ lst_resJ9[i][1] +\n",
    "        '\\nDOI:\\n'+ lst_resDI[i].replace('DOI ','') +\n",
    "        '\\nCitation:\\n'+ lst_resCR[i]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save files:\n",
    "\n",
    "for i in range(len(lst_filename)):\n",
    "    with open(f'./Projects/{lst_filename[i]}', 'xt', encoding='UTF_8') as f:\n",
    "        f.write(lst_filecontent[i])\n",
    "        f.close()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f8763616d36299a7e67065bbff61b4594b946871d4c1b06c8acd4b8a7e0d76f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
