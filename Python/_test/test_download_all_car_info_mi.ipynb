{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit"
  },
  "interpreter": {
   "hash": "4f8763616d36299a7e67065bbff61b4594b946871d4c1b06c8acd4b8a7e0d76f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# using requests lib to get html of each car detail page\r\n",
    "import pandas as pd\r\n",
    "import requests as rq\r\n",
    "import time\r\n",
    "import random\r\n",
    "\r\n",
    "def getHTMLtext(url):\r\n",
    "    header = {\"user-agent\":'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299'}\r\n",
    "    try:\r\n",
    "        response = rq.get(url,headers=header,timeout=30)\r\n",
    "        response.raise_for_status() # If status != 200, cause HTTPError\r\n",
    "    except:\r\n",
    "        return \"get page html Error\"\r\n",
    "    else:\r\n",
    "        response.encoding = 'utf-8'\r\n",
    "        return response.text\r\n",
    "\r\n",
    "def generate_request(dataframe):\r\n",
    "    homepage = 'https://jpxkc.cbex.com'\r\n",
    "\r\n",
    "    for durl in dataframe['deep_url']:\r\n",
    "        url = homepage + durl\r\n",
    "        yield getHTMLtext(url)\r\n",
    "\r\n",
    "def main(dataframe):\r\n",
    "    lst_html = []\r\n",
    "    count = 0\r\n",
    "    for item in generate_request(dataframe):\r\n",
    "        lst_html.append([dataframe['title'][count], item])\r\n",
    "        count += 1\r\n",
    "        time.sleep(1 + random.random() * 2)\r\n",
    "    return lst_html\r\n",
    "\r\n",
    "'''\r\n",
    "INITIATION\r\n",
    "'''\r\n",
    "dtfm_car = pd.read_pickle('car_info_download_comparLst.pkl')\r\n",
    "lst_html = main(dtfm_car)\r\n",
    "\r\n",
    "# homepage = 'https://jpxkc.cbex.com'\r\n",
    "# d_url = dataframe['deep_url'][0]\r\n",
    "# htmltext = getHTMLtext(homepage + d_url)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Final Version of extracting information from html\r\n",
    "# asyncronization try failed: \r\n",
    "import pandas as pd\r\n",
    "from lxml import etree\r\n",
    "import re\r\n",
    "\r\n",
    "def extract_table(html: str):\r\n",
    "    table = pd.read_html(io=html)\r\n",
    "    for dtfm in table:\r\n",
    "        if re.search(r'标的名称', dtfm.to_string(columns=[0])):\r\n",
    "            return dtfm\r\n",
    "\r\n",
    "def extract_accname_via_etree(html: str, extr_len=100):\r\n",
    "    '''\r\n",
    "    actually accn could only be contained in ct4 or ct5, not any ohter place\r\n",
    "    '''\r\n",
    "    h_etree = etree.HTML(html)\r\n",
    "    for i in range(4,6):\r\n",
    "        elem:list = h_etree.xpath(f'//*[@id=\"bd_detail_tab_ct{i}\"]')\r\n",
    "        e2str = etree.tostring(elem[0], method='text', encoding='utf-8').decode('utf-8')\r\n",
    "        try:\r\n",
    "            idx = e2str.index('户名')\r\n",
    "        except ValueError:\r\n",
    "            if not i == 5:\r\n",
    "                continue\r\n",
    "            return 'Not Found \"Account Name\" Signal'\r\n",
    "        else:\r\n",
    "            return e2str[idx + 3 : idx + extr_len].split('，')[0]\r\n",
    "\r\n",
    "def main(lst_html:list):\r\n",
    "    lst1 = []\r\n",
    "    lst2 = []\r\n",
    "    count = 0\r\n",
    "    for html in lst_html:\r\n",
    "        lst1.append(extract_table(html))\r\n",
    "        lst2.append(extract_accname_via_etree(html))\r\n",
    "        count += 1\r\n",
    "        print(f'\\r{1/275:>2.0f}%',end='')\r\n",
    "    return lst1, lst2\r\n",
    "\r\n",
    "if __name__=='__main__':\r\n",
    "    lst_infoTable, lst_accname = main(lst_text)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Try to look up 'deposit values' when requesting HTML with pyppeteer;\r\n",
    "# This is also a try of asynchronious program, but seems no obvious enhancement;\r\n",
    "# This functional module has been saved in D:\\haruk\\Documents\\PythonCodes\\test_async_get_info_from_html.py (code has been provisioned)\r\n",
    "import nest_asyncio\r\n",
    "nest_asyncio.apply()\r\n",
    "import asyncio\r\n",
    "from pyppeteer import launch\r\n",
    "import random\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "def screen_size():\r\n",
    "    import tkinter\r\n",
    "    tk = tkinter.Tk()\r\n",
    "    width = tk.winfo_screenwidth()\r\n",
    "    height = tk.winfo_screenheight()\r\n",
    "    tk.quit()\r\n",
    "    return width, height\r\n",
    "\r\n",
    "async def page_control(url, browser):\r\n",
    "    page = await browser.newPage()\r\n",
    "    # await page.setViewport(viewport={\"width\": width, \"height\": height})\r\n",
    "    await page.setJavaScriptEnabled(enabled=True)\r\n",
    "    await page.setUserAgent(\r\n",
    "        'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 '\r\n",
    "        '(KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36 Edge/16.16299')\r\n",
    "    xpathPromise = asyncio.ensure_future(page.waitForXPath('/html/body/div[6]/div[2]/div[1]/div[2]/div[6]/ul/li[1]/span[3]'))\r\n",
    "    try: # Notify waitForXPath timeout default 30 sec => raise Exception\r\n",
    "        await page.goto(url)  # indirectly cause a navigation(?)\r\n",
    "        await xpathPromise  # Wait until element which matches xpath appears on page\r\n",
    "    except TimeoutError:\r\n",
    "        result = 'TimeoutError'\r\n",
    "    else:\r\n",
    "        target = await page.xpath('/html/body/div[6]/div[2]/div[1]/div[2]/div[6]/ul/li[1]/span[3]')\r\n",
    "        result = await (await target[0].getProperty('textContent')).jsonValue()\r\n",
    "        # task = await asyncio.create_task(target[0].getProperty('textContent'))\r\n",
    "        # done, _ = await asyncio.wait({task})\r\n",
    "        # jshandle = done.result()\r\n",
    "        # result = await jshandle.jsonValue()\r\n",
    "    # await asyncio.sleep(3)\r\n",
    "    # await page_close(browser) # page_close() should surrender to main()\r\n",
    "    await page.close()\r\n",
    "    return result\r\n",
    "\r\n",
    "async def page_close(browser, preserve=1):\r\n",
    "    prs_pages = await browser.pages()\r\n",
    "    for _page in prs_pages:\r\n",
    "        prs = len(prs_pages)\r\n",
    "        while prs > preserve:\r\n",
    "            await _page.close()\r\n",
    "\r\n",
    "def create_lst_task_url(dataframe, lst_tsk_len:int):\r\n",
    "    homepage = 'https://jpxkc.cbex.com'\r\n",
    "    srs_url = dataframe['deep_url']\r\n",
    "    srs_tit = dataframe['title']\r\n",
    "    lst_task_url = []\r\n",
    "    lst_title = []\r\n",
    "    for i in range(len(srs_url)//lst_tsk_len):\r\n",
    "        imlst_1 = []\r\n",
    "        imlst_2 = []\r\n",
    "        for k in range(lst_tsk_len):\r\n",
    "            imlst_1.append(homepage + srs_url[i * lst_tsk_len + k])\r\n",
    "            imlst_2.append(srs_tit[i * lst_tsk_len + k])\r\n",
    "        lst_task_url.append(imlst_1)\r\n",
    "        lst_title.append(imlst_2)\r\n",
    "    imlst_1 = []\r\n",
    "    imlst_2 = []\r\n",
    "    for i in range(len(srs_url) - len(srs_url)%lst_tsk_len, len(srs_url)):\r\n",
    "        imlst_1.append(homepage + srs_url[i])\r\n",
    "        imlst_2.append(srs_tit[i])\r\n",
    "    lst_task_url.append(imlst_1)\r\n",
    "    lst_title.append(imlst_2)\r\n",
    "    return lst_task_url, lst_title\r\n",
    "\r\n",
    "async def main(lst_task_url):\r\n",
    "    # lst_task_url should be a 2D url list; len of second dimens defines concurrently running no.\r\n",
    "    browser = await launch({'headless': False, 'userDataDir': r'D:/haruk/Documents/PythonCodes/Temp', 'args': ['--no-sandbox'], 'dumpio': True})\r\n",
    "    # encapsule coroutine (lst_task)\r\n",
    "    lst_task = []\r\n",
    "    for item in lst_task_url[:2]:\r\n",
    "        imlst = []\r\n",
    "        for subitem in item:\r\n",
    "            imlst.append(page_control(url=subitem, browser=browser))\r\n",
    "        lst_task.append(imlst)\r\n",
    "    # execute tasks\r\n",
    "    lst_result = []\r\n",
    "    for i in range(len(lst_task)):\r\n",
    "        result = await asyncio.gather(*lst_task[i])\r\n",
    "        lst_result.append(result)\r\n",
    "        # await page_close(browser) # seems browser.pages() cannot connect to the page that has already been assigned a handle name\r\n",
    "    # await browser.close() # Please manually close the chrome\r\n",
    "    return lst_result\r\n",
    "\r\n",
    "'''\r\n",
    "INITIATION\r\n",
    "'''\r\n",
    "lst_task_url, lst_title = create_lst_task_url(dataframe=dtfm_car, lst_tsk_len=8)\r\n",
    "\r\n",
    "loop = asyncio.get_event_loop()\r\n",
    "lst_depoVal = loop.run_until_complete(main(lst_task_url))\r\n",
    "\r\n",
    "# width, height = screen_size()\r\n",
    "# p_url = 'https://jpxkc.cbex.com/jpxkc/prj/detail/157387.html'\r\n",
    "\r\n",
    "# await asyncio.wait([\r\n",
    "    #     page.click('a.my-link'),\r\n",
    "    #     page.waitForNavigation(),\r\n",
    "    # ])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### The first successful run (functional success) yield following Exception:\r\n",
    "\r\n",
    "This may be due to ipython interactive module has already got a run of async loop (?)\r\n",
    "\r\n",
    "> D:\\Program Files\\Python\\Python39\\lib\\site-packages\\pyppeteer\\util.py:29:  \r\n",
    "> \r\n",
    "> RuntimeWarning: coroutine 'page_control' was never awaited  \r\n",
    ">   `gc.collect()`  \r\n",
    "> RuntimeWarning: Enable tracemalloc to get the object allocation traceback  \r\n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "# This and following cell are strings provision and data concatenation\r\n",
    "import re\r\n",
    "\r\n",
    "def split_string_1(dtfm: pd.DataFrame):\r\n",
    "    srs_a = dtfm['拟提供的文件']\r\n",
    "    lst1, lst2, lst3 = [], [], []\r\n",
    "    for i in srs_a:\r\n",
    "        temp = i.split('、')\r\n",
    "        for i in range(len(temp)):\r\n",
    "            temp[i] = re.sub(r'[\\s123；]',repl='',string=temp[i])\r\n",
    "        lst1.append(temp[1])\r\n",
    "        lst2.append(temp[2])\r\n",
    "        lst3.append(temp[3])\r\n",
    "    dct = {'file_1': lst1, 'file_2': lst2, 'file_3':lst3}\r\n",
    "    dtfm_app = pd.DataFrame(dct)\r\n",
    "    dtfm = pd.concat(objs=[dtfm, dtfm_app], axis=1)\r\n",
    "    return dtfm\r\n",
    "\r\n",
    "srs_a = dtfm[dtfm.columns[11]]\r\n",
    "\r\n",
    "\r\n",
    "def split_string_2(srs:pd.Series):\r\n",
    "    lst_r1 = []\r\n",
    "    lst_r2 = []\r\n",
    "    for item in srs:\r\n",
    "        lst_idx = []\r\n",
    "        for i in range(1,7):\r\n",
    "            try:\r\n",
    "                idx = re.search(f'{i}、',item).span()[0]\r\n",
    "            except:\r\n",
    "                pass\r\n",
    "            else:\r\n",
    "                lst_idx.append(idx+1)\r\n",
    "        lst_val = []\r\n",
    "        lst_nam = []\r\n",
    "        for i in range(len(lst_idx)-1):\r\n",
    "            if lst_idx[i]:\r\n",
    "                targ = item[lst_idx[i]: lst_idx[i+1]-1].split('：')\r\n",
    "                try:\r\n",
    "                    name = targ[0]\r\n",
    "                    value = targ[1]\r\n",
    "                except:\r\n",
    "                    name = None\r\n",
    "                    value = targ[0]\r\n",
    "                lst_nam.append(name)               \r\n",
    "                lst_val.append(value)\r\n",
    "        targ_last = item[lst_idx[-1]:].split('：')\r\n",
    "        try:\r\n",
    "            name = targ_last[0]\r\n",
    "            value = targ_last[1]\r\n",
    "        except:\r\n",
    "            name = None\r\n",
    "            value = targ_last[0]\r\n",
    "        lst_nam.append(name)               \r\n",
    "        lst_val.append(value)\r\n",
    "        lst_r1.append(lst_val)\r\n",
    "        lst_r2.append(lst_nam)\r\n",
    "    return lst_r1, lst_r2\r\n",
    "\r\n",
    "lst_values, lst_names = split_string(srs_a)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "for i in range(len(lst_values)):\r\n",
    "    temp = re.sub(r'[\\D]',repl=\"_\", string=lst_values[i][-1]).strip('_')\r\n",
    "    temp_lst = temp.split('_')\r\n",
    "    for k in temp_lst:\r\n",
    "        lst_values[i].append(k)\r\n",
    "\r\n",
    "for r in range(len(lst_values)):\r\n",
    "    for ite in range(len(lst_values[r])):\r\n",
    "        lst_values[r][ite] = re.sub(r'[、\\s\\xa0\\u3000]', repl=\"\",string=lst_values[r][ite])\r\n",
    "\r\n",
    "for i in range(len(lst_values)):\r\n",
    "    if len(lst_values[i]) < 9:\r\n",
    "        for k in range(9-len(lst_values[i])):\r\n",
    "            lst_values[i].append(-1)\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "ary = np.array(lst_values)\r\n",
    "dct = {}\r\n",
    "for i in range(len(lst_values[0])):\r\n",
    "    try:\r\n",
    "        if indexs[i]:\r\n",
    "            dct[indexs[i]] = ary[:,i]\r\n",
    "        else:\r\n",
    "            dct[f'col_{i}'] = ary[:,i]\r\n",
    "    except:\r\n",
    "        dct[f'col_{i}'] = ary[:,i]\r\n",
    "dtfm_sv = pd.DataFrame(dct)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  }
 ]
}